{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXRF0sEJwLv/wn9tklKY8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amogh24/Fake_news/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ziiso-5CKxBR"
      },
      "source": [
        "from google.colab import drive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0enhIZELEuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8573cfb-1669-436d-d409-ecaf7bcc4b9c"
      },
      "source": [
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuI3MxVBZfO0",
        "outputId": "2211863a-e371-441b-c092-27d6b0f2af6f"
      },
      "source": [
        "import sys\n",
        "import csv\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "csv.field_size_limit(100000000)\n",
        "csv.field_size_limit(sys.maxsize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuOtcsmELZKS"
      },
      "source": [
        "import pandas as pd\n",
        "raw_news=pd.read_csv('/content/gdrive/MyDrive/fake-news/train.csv',engine='python')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEoM-ig1Zy3v"
      },
      "source": [
        "true_raw_news=raw_news[raw_news['label']==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p28ny4xtaCYN",
        "outputId": "a6e8b388-f3ef-4da6-8755-373aa3935190"
      },
      "source": [
        "true_raw_news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
              "      <td>Daniel Nussbaum</td>\n",
              "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
              "      <td>Alissa J. Rubin</td>\n",
              "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Excerpts From a Draft Script for Donald Trump’...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Donald J. Trump is scheduled to make a highly ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
              "      <td>Megan Twohey and Scott Shane</td>\n",
              "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "1   1  ...     0\n",
              "5   5  ...     0\n",
              "7   7  ...     0\n",
              "8   8  ...     0\n",
              "9   9  ...     0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wwfuxvyYbq-O",
        "outputId": "fc04571d-bfef-42e3-f2a2-2abce3060b10"
      },
      "source": [
        "fake_raw_news=raw_news[raw_news['label']==1]\n",
        "fake_raw_news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "6   6  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDy-4neFbyXV"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "rF8QhMiHcLXn",
        "outputId": "b19f9ff7-f95f-47f7-994e-11fb396f1040"
      },
      "source": [
        "target = raw_news['label']\n",
        "sns.set_style('darkgrid')\n",
        "sns.countplot(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f92af504f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ZdSYEAgPW4"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9z-xaG6Gnwf"
      },
      "source": [
        "import torchtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDIXaFmX3Vnt",
        "outputId": "2423b575-7602-4b7a-e486-9e96c0c10fa7"
      },
      "source": [
        "\n",
        "import string\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "punct = set(string.punctuation)\n",
        "t={'\\n'}\n",
        "stopwords = set(stopwords.words('english'))\n",
        "#s=stopwords.union(punct)\n",
        "s=punct.union(t)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsRY2AElHKTg"
      },
      "source": [
        "import spacy\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenizer(text): # create a tokenizer function\n",
        "\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "#TEXT = torchtext.data.Field(preprocessing=getClearReview,sequential=True, lower=True,tokenize=tokenizer)\n",
        "TEXT = torchtext.legacy.data.Field(sequential=True, lower=True,tokenize=tokenizer,use_vocab=True,stop_words=s,fix_length=700)\n",
        "#TEXT = torchtext.data.Field(sequential=True, lower=True,use_vocab=True,fix_length=700)\n",
        "LABEL = torchtext.legacy.data.Field(sequential=False, use_vocab=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmobdrOfHoG-"
      },
      "source": [
        "fields = [(None, None),(None, None),(None, None), ('text',TEXT),('label', LABEL)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40pI2kT-kgLD"
      },
      "source": [
        "training_data=torchtext.legacy.data.TabularDataset(path = '/content/gdrive/MyDrive/fake-news/train.csv',format = 'csv',fields = fields,skip_header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s4o9aTJk7pI"
      },
      "source": [
        "#print(vars(training_data.examples[0]))\n",
        "TEXT.build_vocab(training_data)\n",
        "LABEL.build_vocab(training_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PImqV5WRlzj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebce1899-c860-4be3-b657-a27590350eb7"
      },
      "source": [
        "from torchtext import vocab\n",
        "glove=vocab.Vectors(\"glove.6B.50d.txt\",\"/content/gdrive/MyDrive/\")\n",
        "TEXT.build_vocab(training_data,vectors='glove.6B.100d',unk_init=torch.Tensor.zero_,max_size=50000) \n",
        "LABEL.build_vocab(training_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.34MB/s]                           \n",
            "100%|█████████▉| 398146/400000 [00:14<00:00, 26692.46it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fxY8AZ5859j"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_Lbf9_KH8bW"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG_y_ISOIG86",
        "outputId": "0ed6360a-d116-49fb-ab64-5ea6f9b4525a"
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "print(\"Cuda Status on system is {}\".format(is_cuda))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda Status on system is True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iaj0IDqO35g"
      },
      "source": [
        "\n",
        "VOCAB_SIZE = 194298\n",
        "EMBED_DIM = 100\n",
        "\n",
        "embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pR-fMD7UW67",
        "outputId": "0662c9f1-ed28-4941-8a19-cea26e9e77be"
      },
      "source": [
        "embedding.weight.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([194298, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bzpyd7KWDcx"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6xTw3SjWMRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1dd736d-dea9-4596-9355-c95863f2ab7d"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 50002\n",
            "Unique tokens in LABEL vocabulary: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUQoHly0uNv1",
        "outputId": "9dfdc596-4b05-48d8-8345-7136876f5209"
      },
      "source": [
        "train_iter = torchtext.legacy.data.BucketIterator(\n",
        "    \n",
        "                              # Datasets for iterator to draw data from\n",
        "                              (training_data),\n",
        "\n",
        "                              # Tuple of train and validation batch sizes.\n",
        "                              batch_size=64,\n",
        "\n",
        "                              # Device to load batches on.\n",
        "                              device=device, \n",
        "\n",
        "                              # Function to use for sorting examples.\n",
        "                              sort_key=lambda x: len(x.text),\n",
        "\n",
        "\n",
        "                              # Repeat the iterator for multiple epochs.\n",
        "                              #repeat=True, \n",
        "\n",
        "                              # Sort all examples in data using `sort_key`.\n",
        "                              sort=True, \n",
        "\n",
        "                              # Shuffle data on each epoch run.\n",
        "                              shuffle=True,\n",
        "\n",
        "                              # Use `sort_key` to sort examples in each batch.\n",
        "                              \n",
        "                              )\n",
        "\n",
        "# Print number of batches in each split.\n",
        "print('Created `train_iter` with %d batches!'%len(train_iter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created `train_iter` with 325 batches!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bDJJp-nRrId",
        "outputId": "6f4b1be4-ba6f-4201-f8d1-cc58731406c9"
      },
      "source": [
        "\n",
        "print(type(train_iter))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchtext.legacy.data.iterator.BucketIterator'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bbJPgQSaTn"
      },
      "source": [
        "\n",
        "train_dataloader = (train_iter)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFesNSaHTFl4",
        "outputId": "4edd8762-7125-41fe-b2fc-f6f97f338141"
      },
      "source": [
        "iterator = train_dataloader\n",
        "print(len(list(iterator)))\n",
        "print(type(list(iterator)))\n",
        "print(iterator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 398146/400000 [00:30<00:00, 26692.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "325\n",
            "<class 'list'>\n",
            "<torchtext.legacy.data.iterator.BucketIterator object at 0x7f9246bc1810>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1dsoWDOv3le",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "a49b1e10-2ae6-4566-8d6e-c2dc97cf2133"
      },
      "source": [
        "model = SWEMWithEmbeddings(\n",
        "    vocab_size = 194298,\n",
        "    embedding_size = 100, \n",
        "    hidden_dim1 = 80,\n",
        "    dim2 = 40, \n",
        "    num_outputs = 1,\n",
        ")\n",
        "weights=list(model.parameters())\n",
        "\n",
        "# Binary cross-entropy (BCE) Loss and Adam Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "# Iterate through train set minibatchs \n",
        "for epoch in range(100):\n",
        "    correct = 0\n",
        "    num_examples = 0\n",
        "    \n",
        "    #for (inputs,labels) in enumerate(train_dataloader):\n",
        "    for batch in train_dataloader:\n",
        "        # Zero out the gradients\n",
        "        inputs=batch.text\n",
        "        labels=batch.label\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        y = model(inputs)\n",
        "        yr = torch.round(y)\n",
        "       \n",
        "        \n",
        "        labels=labels.unsqueeze(1)\n",
        "        labels=labels.float()\n",
        "        labels=torch.sub(labels,1,alpha=1)\n",
        "        \n",
        "        loss = criterion(yr, labels)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        \n",
        "        correct += torch.sum((yr == labels).float())\n",
        "        num_examples += len(inputs)\n",
        "    \n",
        "    # Print training progress\n",
        "    if epoch % 1 == 0:\n",
        "        acc = correct/num_examples\n",
        "        print(weights[0].grad)\n",
        "        print(\"Epoch: {0} \\t Train Loss: {1} \\t Train Acc: {2}\".format(epoch, loss, acc))\n",
        "\n",
        "## Testing\n",
        "# correct = 0\n",
        "# num_test = 0\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     # Iterate through test set minibatchs \n",
        "#     for inputs, labels in test_loader:\n",
        "#         # Forward pass\n",
        "#         y = model(inputs)\n",
        "        \n",
        "#         predictions = torch.round(torch.sigmoid(y))\n",
        "#         correct += torch.sum((predictions == labels).float())\n",
        "#         num_test += len(inputs)\n",
        "    \n",
        "# print('Test accuracy: {}'.format(correct/num_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a9f3a8077e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = SWEMWithEmbeddings(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m194298\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0membedding_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhidden_dim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SWEMWithEmbeddings' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhSefQf59Ahw"
      },
      "source": [
        "from torch.nn.utils.rnn \n",
        "\n",
        "ret = [glove.get_vecs_by_tokens(i.text)  for i in training_data[0:5]]\n",
        "   \n",
        "rets=pad_sequence(ret)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iFP-iLg9FGY"
      },
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, input_size, hidden_dim1,dim2, num_outputs):\n",
        "        super(Linear,self).__init__()\n",
        "       \n",
        "        self.fc1 = nn.Linear(input_size, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, dim2)\n",
        "        self.fc3 = nn.Linear(dim2,num_outputs)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        \n",
        "\n",
        "    def forward(self, text):\n",
        "        #text=self.embedding(text)\n",
        "        #text=text.view(text.size()[0],-1)\n",
        "        text=text.float()\n",
        "\n",
        "        h1 = self.fc1(text)\n",
        "        h1 = torch.sigmoid(h1)\n",
        "        h1= self.dropout(h1)\n",
        "        h2 = self.fc2(h1)\n",
        "        h2 = F.relu(h2)\n",
        "        h3 = self.fc3(h2)\n",
        "        \n",
        "        \n",
        "        return (h3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTv84ru39Jeq"
      },
      "source": [
        "model = Linear(\n",
        "    input_size=700,\n",
        "    hidden_dim1 = 300,\n",
        "    dim2=100,\n",
        "    num_outputs = 1,\n",
        ")\n",
        "\n",
        "weights=list(model.parameters())\n",
        "for w in weights:\n",
        "  print(w.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JriAR92r9M4n"
      },
      "source": [
        "\n",
        "# Binary cross-entropy (BCE) Loss and Adam Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Iterate through train set minibatchs \n",
        "for epoch in range(500):\n",
        "    correct = 0\n",
        "    num_examples = 0\n",
        "    \n",
        "    #for (inputs,labels) in enumerate(train_dataloader):\n",
        "    for batch in train_dataloader:\n",
        "        # Zero out the gradients\n",
        "        #inputs=batch.text\n",
        "        \n",
        "        text=batch.text\n",
        "               \n",
        "        text=text.view(64,700)\n",
        "        labels=batch.label\n",
        "        #inputs=inputs.view(64,700)\n",
        "        #inputs=inputs.float()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        #y = model(inputs)\n",
        "        y=model(text)\n",
        "        yr = torch.squeeze(torch.round(torch.sigmoid(y)))\n",
        "        \n",
        "        yr=yr.float()\n",
        "        \n",
        "        labels=torch.sub(labels,1,alpha=1)\n",
        "        labels=labels.float()\n",
        "        \n",
        "        \n",
        "        loss = criterion(yr, labels)\n",
        "        \n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        \n",
        "        correct += torch.sum((yr == labels).float())\n",
        "        num_examples += len(text)\n",
        "    \n",
        "    # Print training progress\n",
        "    if epoch % 5 == 0:\n",
        "          \n",
        "        acc = (correct/num_examples)*100\n",
        "        print(weights[0].grad)\n",
        "        \n",
        "        print(\"Epoch: {0} \\t Train Loss: {1} \\t Train Acc: {2}\".format(epoch, loss, acc))\n",
        "        #print(\"Epoch: {0} \\t Train Loss: {1} \\t Correct: {2}\".format(epoch, loss, correct))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSrOPrTVsHMQ"
      },
      "source": [
        "for batch in train_dataloader:\n",
        "  print(glove.get_vecs_by_tokens(batch.text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_LRMCiqEFzZ"
      },
      "source": [
        "ret = [glove.get_vecs_by_tokens(i.text)  for i in training_data[0:5]]\n",
        "print(ret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMWyRs0aFocz"
      },
      "source": [
        "sentences=['hello','hi']\n",
        "print(glove.get_vecs_by_tokens(sentences[1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH7AOlr6G922"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "   def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "     super().__init__()\n",
        "        \n",
        "     self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "     self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "     self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "   def forward(self, x):\n",
        "\n",
        "        #x = [sent len, batch size]\n",
        "        \n",
        "       embedded = self.embedding(x)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "       output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "       assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "       \n",
        "       out = self.fc(hidden)\n",
        "       return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz-WBnco9n0f"
      },
      "source": [
        "class Linear_rnn(nn.Module):\n",
        "   def __init__(self, input_dim, embedding_dim, hidden_dim, hidden_dim2,dim2, output_dim):\n",
        "     super().__init__()\n",
        "        \n",
        "     self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "     self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "     self.fc1 = nn.Linear(hidden_dim, hidden_dim2)\n",
        "     self.rnn2= nn.LSTM(hidden_dim2,dim2)\n",
        "     self.fc2 = nn.Linear(dim2,output_dim)\n",
        "     \n",
        "\n",
        "   def forward(self, x):\n",
        "\n",
        "        #x = [sent len, batch size]\n",
        "        # print(x.shape)\n",
        "       embedded = self.embedding(x)\n",
        "       \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "       output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "      #  assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "       output=output.reshape(-1,hidden_dim)\n",
        "       out = self.fc1(hidden)\n",
        "       a,b=self.rnn2(out)\n",
        "       a=a.reshape(-1,dim2)\n",
        "      #  assert torch.equal(a[-1,:,:], b.squeeze(0))\n",
        "       res = self.fc2(b)\n",
        "       return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg2VUdml1JBQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "5057400f-f6eb-49f9-8612-fd0efc3683bc"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 374\n",
        "OUTPUT_DIM = 2\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-bda6d11c30cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mOUTPUT_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3UarR9m-FmL"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 374\n",
        "Dim2=80\n",
        "OUTPUT_DIM = 2\n",
        "HIDDEN_DIM2=200\n",
        "\n",
        "model2 = Linear_rnn(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM,HIDDEN_DIM2,Dim2, OUTPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgrBOtNu1Z5e",
        "outputId": "0d89781f-3d71-4231-e8f8-9c8f7af1c556"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHJr-q4S-d99"
      },
      "source": [
        "model2.embedding.weight.data = pretrained_embeddings.cuda()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
        "model2 = model2.to(device)\n",
        "class_weights = torch.tensor([1.0, 15.0]).cuda()\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9nGBaj81wua"
      },
      "source": [
        "model.embedding.weight.data = pretrained_embeddings.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DrzM6ak11Q3"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ME94w__18TS"
      },
      "source": [
        "class_weights = torch.tensor([1.0, 15.0]).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOP5x6ec2FiZ"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkQM5IWfIm5l"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxl_00F2L6N"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    preds, ind= torch.max(F.softmax(preds, dim=-1), 1)\n",
        "    correct = (ind == y).float()\n",
        "    acc = correct.sum()/float(len(correct))\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKWriuRC2VSn"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        labels=batch.label       \n",
        "        predictions = model(batch.text).squeeze(0)\n",
        "        labels=torch.sub(labels,1,alpha=1)\n",
        "#         print(predictions.shape, batch.Label.shape, model(batch.Text).shape)\n",
        "        loss = criterion(predictions, labels)\n",
        "#         print(loss.shape)\n",
        "        acc = binary_accuracy(predictions, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKRerj-F2c6W",
        "outputId": "97141e6a-6003-4be3-d902-f7a80e39b9d6"
      },
      "source": [
        "N_EPOCHS=150\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "    print(train_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5490865384615384\n",
            "0.5444711538461539\n",
            "0.5872115384615385\n",
            "0.5549038461538461\n",
            "0.5509615384615385\n",
            "0.5545673076923077\n",
            "0.5525\n",
            "0.5548557692307692\n",
            "0.5550480769230769\n",
            "0.5655288461538461\n",
            "0.5571153846153846\n",
            "0.5591826923076924\n",
            "0.5565384615384615\n",
            "0.5567307692307693\n",
            "0.5595192307692308\n",
            "0.5465384615384615\n",
            "0.5534134615384615\n",
            "0.5523557692307692\n",
            "0.551875\n",
            "0.5514903846153846\n",
            "0.5507211538461538\n",
            "0.5494230769230769\n",
            "0.5492788461538461\n",
            "0.5505288461538461\n",
            "0.5494230769230769\n",
            "0.556826923076923\n",
            "0.5611538461538461\n",
            "0.5641826923076924\n",
            "0.5703846153846154\n",
            "0.5779807692307692\n",
            "0.5867788461538461\n",
            "0.5992788461538462\n",
            "0.5904326923076924\n",
            "0.6048076923076923\n",
            "0.6076442307692308\n",
            "0.6280769230769231\n",
            "0.6303846153846154\n",
            "0.630625\n",
            "0.6142788461538462\n",
            "0.6253365384615385\n",
            "0.6175480769230769\n",
            "0.6115384615384616\n",
            "0.6105288461538462\n",
            "0.6113942307692307\n",
            "0.6211057692307692\n",
            "0.5670673076923077\n",
            "0.5535096153846154\n",
            "0.5642307692307692\n",
            "0.5691346153846154\n",
            "0.5773076923076923\n",
            "0.5776442307692308\n",
            "0.5759134615384616\n",
            "0.5673557692307692\n",
            "0.5687980769230769\n",
            "0.5653365384615384\n",
            "0.5641826923076924\n",
            "0.5665384615384615\n",
            "0.5728365384615385\n",
            "0.5696634615384616\n",
            "0.5736057692307692\n",
            "0.5726923076923077\n",
            "0.5753846153846154\n",
            "0.5821153846153846\n",
            "0.5819230769230769\n",
            "0.5952403846153846\n",
            "0.589375\n",
            "0.5844230769230769\n",
            "0.588173076923077\n",
            "0.5754326923076923\n",
            "0.5915865384615384\n",
            "0.5877884615384615\n",
            "0.5771634615384615\n",
            "0.5728365384615385\n",
            "0.5828846153846153\n",
            "0.5820673076923077\n",
            "0.5805769230769231\n",
            "0.5826442307692308\n",
            "0.5804807692307692\n",
            "0.5844230769230769\n",
            "0.5647596153846154\n",
            "0.5794711538461539\n",
            "0.5852403846153846\n",
            "0.5747115384615384\n",
            "0.5684134615384615\n",
            "0.5670673076923077\n",
            "0.5719711538461538\n",
            "0.5712980769230769\n",
            "0.5720673076923077\n",
            "0.5713942307692308\n",
            "0.5716346153846154\n",
            "0.5763461538461538\n",
            "0.5790384615384615\n",
            "0.57875\n",
            "0.5829807692307692\n",
            "0.588798076923077\n",
            "0.589375\n",
            "0.5701923076923077\n",
            "0.5840384615384615\n",
            "0.5860576923076923\n",
            "0.5845192307692307\n",
            "0.5909134615384616\n",
            "0.5879807692307693\n",
            "0.5762019230769231\n",
            "0.5801442307692307\n",
            "0.5682692307692307\n",
            "0.5770192307692308\n",
            "0.5869230769230769\n",
            "0.590625\n",
            "0.5922596153846154\n",
            "0.5957211538461539\n",
            "0.5979807692307693\n",
            "0.6016346153846154\n",
            "0.6059615384615384\n",
            "0.609423076923077\n",
            "0.6132211538461538\n",
            "0.6162980769230769\n",
            "0.6197115384615385\n",
            "0.6229807692307693\n",
            "0.6277403846153846\n",
            "0.6289903846153846\n",
            "0.6326442307692308\n",
            "0.6346153846153846\n",
            "0.6386538461538461\n",
            "0.6418269230769231\n",
            "0.6295673076923077\n",
            "0.6121153846153846\n",
            "0.6142307692307692\n",
            "0.6210576923076923\n",
            "0.6257211538461539\n",
            "0.6283173076923076\n",
            "0.6333173076923077\n",
            "0.6269711538461539\n",
            "0.6423076923076924\n",
            "0.6435096153846154\n",
            "0.6486538461538461\n",
            "0.6269711538461539\n",
            "0.6022596153846154\n",
            "0.613125\n",
            "0.6235096153846154\n",
            "0.6302403846153846\n",
            "0.6399519230769231\n",
            "0.6441826923076923\n",
            "0.6547596153846154\n",
            "0.6573076923076923\n",
            "0.6601923076923077\n",
            "0.6602884615384615\n",
            "0.6560096153846153\n",
            "0.6541346153846154\n",
            "0.6541346153846154\n",
            "0.6519230769230769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVa4rIUQ2vWx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "00bb9cc7-6a9c-4c66-be33-44129f5fdef1"
      },
      "source": [
        "N_EPOCHS=150\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(model2, train_dataloader, optimizer, criterion)\n",
        "    print(train_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-0c3c47da70a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-3ca37f57a3b3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         print(predictions.shape, batch.Label.shape, model(batch.Text).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-a10b8958f24d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;31m#  assert torch.equal(output[-1,:,:], hidden.squeeze(0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m        \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m        \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m        \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hidden_dim' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFqLN3Ya-z8i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}