{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPMCoQKbd3njeMHJ3Ls3zrj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amogh24/Fake_news/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ziiso-5CKxBR"
      },
      "source": [
        "from google.colab import drive\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0enhIZELEuE",
        "outputId": "5d06d356-33c5-481c-d2d2-5ec76ba653d0"
      },
      "source": [
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuI3MxVBZfO0",
        "outputId": "b5c22cd8-7a82-4cfd-dc30-37f1aababd9c"
      },
      "source": [
        "import sys\n",
        "import csv\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "csv.field_size_limit(100000000)\n",
        "csv.field_size_limit(sys.maxsize)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuOtcsmELZKS"
      },
      "source": [
        "import pandas as pd\n",
        "raw_news=pd.read_csv('/content/gdrive/MyDrive/fake-news/train.csv',engine='python')\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEoM-ig1Zy3v"
      },
      "source": [
        "true_raw_news=raw_news[raw_news['label']==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p28ny4xtaCYN",
        "outputId": "88ae776c-0cc8-4787-eda1-e0f6d0807fd7"
      },
      "source": [
        "true_raw_news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
              "      <td>Daniel Nussbaum</td>\n",
              "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
              "      <td>Alissa J. Rubin</td>\n",
              "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Excerpts From a Draft Script for Donald Trump’...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Donald J. Trump is scheduled to make a highly ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
              "      <td>Megan Twohey and Scott Shane</td>\n",
              "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "1   1  ...     0\n",
              "5   5  ...     0\n",
              "7   7  ...     0\n",
              "8   8  ...     0\n",
              "9   9  ...     0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wwfuxvyYbq-O",
        "outputId": "c372529a-ff7b-4977-e172-fed328bc774d"
      },
      "source": [
        "fake_raw_news=raw_news[raw_news['label']==1]\n",
        "fake_raw_news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "6   6  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDy-4neFbyXV"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "rF8QhMiHcLXn",
        "outputId": "a04fab56-fefc-4936-c22d-9bcb827556b7"
      },
      "source": [
        "target = raw_news['label']\n",
        "sns.set_style('darkgrid')\n",
        "sns.countplot(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f120b1e2610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ZdSYEAgPW4"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9z-xaG6Gnwf"
      },
      "source": [
        "import torchtext"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDIXaFmX3Vnt",
        "outputId": "c08cbf2d-8e36-4371-af9f-2fa5c1d4f290"
      },
      "source": [
        "\n",
        "import string\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "punct = set(string.punctuation)\n",
        "t={'\\n'}\n",
        "stopwords = set(stopwords.words('english'))\n",
        "#s=stopwords.union(punct)\n",
        "s=punct.union(t)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsRY2AElHKTg"
      },
      "source": [
        "import spacy\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenizer(text): # create a tokenizer function\n",
        "\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "#TEXT = torchtext.data.Field(preprocessing=getClearReview,sequential=True, lower=True,tokenize=tokenizer)\n",
        "TEXT = torchtext.legacy.data.Field(sequential=True, lower=True,tokenize=tokenizer,use_vocab=True,stop_words=s,fix_length=700)\n",
        "#TEXT = torchtext.data.Field(sequential=True, lower=True,use_vocab=True,fix_length=700)\n",
        "LABEL = torchtext.legacy.data.Field(sequential=False, use_vocab=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmobdrOfHoG-"
      },
      "source": [
        "fields = [(None, None),(None, None),(None, None), ('text',TEXT),('label', LABEL)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40pI2kT-kgLD"
      },
      "source": [
        "training_data=torchtext.legacy.data.TabularDataset(path = '/content/gdrive/MyDrive/fake-news/train.csv',format = 'csv',fields = fields,skip_header = True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s4o9aTJk7pI"
      },
      "source": [
        "#print(vars(training_data.examples[0]))\n",
        "TEXT.build_vocab(training_data)\n",
        "LABEL.build_vocab(training_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyVrRkziAuOu"
      },
      "source": [
        "def convert(line):\n",
        "  if len(line.text)>0:\n",
        "    y = line.label\n",
        "    embeddings = [wordVector[word]  for word in line.text if word in all]\n",
        "    x=np.vstack(embeddings)\n",
        "    if len(x)>0:return x ,y \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PImqV5WRlzj-"
      },
      "source": [
        "from torchtext import vocab\n",
        "glove=vocab.Vectors(\"glove.6B.50d.txt\",\"/content/gdrive/MyDrive/\")\n",
        "TEXT.build_vocab(training_data,vectors='glove.6B.100d',unk_init=torch.Tensor.zero_,max_size=50000) \n",
        "LABEL.build_vocab(training_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-czyIo0qhqZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0ee434-573f-45bb-b392-64ce8d0feda2"
      },
      "source": [
        "print(LABEL.vocab.freqs)\n",
        "print(len(LABEL.vocab.freqs))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'1': 10413, '0': 10387})\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS50q_XTzDuv"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_Lbf9_KH8bW"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG_y_ISOIG86",
        "outputId": "561dee46-091e-4e17-d03a-e0186af2c96a"
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "print(\"Cuda Status on system is {}\".format(is_cuda))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda Status on system is True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iaj0IDqO35g"
      },
      "source": [
        "\n",
        "VOCAB_SIZE = 194298\n",
        "EMBED_DIM = 100\n",
        "\n",
        "embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pR-fMD7UW67",
        "outputId": "feef232b-3c28-4bf6-f6a6-d1dceebf1f42"
      },
      "source": [
        "embedding.weight.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([194298, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynBgS8efUrI_"
      },
      "source": [
        "class SWEMWithEmbeddings(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_dim1,dim2, num_outputs):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.fc1 = nn.Linear(embedding_size, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, dim2)\n",
        "        self.fc3 = nn.Linear(dim2,num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)\n",
        "        embed_mean = torch.mean(embed, dim=0)\n",
        "        h = self.fc1(embed_mean)\n",
        "        rh = F.relu(h)\n",
        "        h2 = self.fc2(rh)\n",
        "        rh2 = F.relu(h2)\n",
        "        h3 = self.fc3(rh2)\n",
        "        return (h3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bzpyd7KWDcx"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6xTw3SjWMRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a60db1-395e-49d1-e43d-e860123660bc"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 194298\n",
            "Unique tokens in LABEL vocabulary: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUQoHly0uNv1",
        "outputId": "d07725c1-6983-4707-b049-4024c3235aca"
      },
      "source": [
        "train_iter = torchtext.legacy.data.BucketIterator(\n",
        "    \n",
        "                              # Datasets for iterator to draw data from\n",
        "                              (training_data),\n",
        "\n",
        "                              # Tuple of train and validation batch sizes.\n",
        "                              batch_size=64,\n",
        "\n",
        "                              # Device to load batches on.\n",
        "                              device=device, \n",
        "\n",
        "                              # Function to use for sorting examples.\n",
        "                              sort_key=lambda x: len(x.text),\n",
        "\n",
        "\n",
        "                              # Repeat the iterator for multiple epochs.\n",
        "                              #repeat=True, \n",
        "\n",
        "                              # Sort all examples in data using `sort_key`.\n",
        "                              sort=True, \n",
        "\n",
        "                              # Shuffle data on each epoch run.\n",
        "                              shuffle=True,\n",
        "\n",
        "                              # Use `sort_key` to sort examples in each batch.\n",
        "                              \n",
        "                              )\n",
        "\n",
        "# Print number of batches in each split.\n",
        "print('Created `train_iter` with %d batches!'%len(train_iter))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created `train_iter` with 325 batches!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bDJJp-nRrId",
        "outputId": "a1d263a6-af90-440f-d95e-81347bc79636"
      },
      "source": [
        "\n",
        "print(type(train_iter))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchtext.legacy.data.iterator.BucketIterator'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bbJPgQSaTn"
      },
      "source": [
        "\n",
        "train_dataloader = (train_iter)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFesNSaHTFl4",
        "outputId": "25ada895-0c25-4007-90fb-07e4e6c3407f"
      },
      "source": [
        "iterator = train_dataloader\n",
        "print(len(list(iterator)))\n",
        "print(type(list(iterator)))\n",
        "print(iterator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "325\n",
            "<class 'list'>\n",
            "<torchtext.legacy.data.iterator.BucketIterator object at 0x7fbc74c6e2d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "y1dsoWDOv3le",
        "outputId": "648ab593-b056-4327-f469-850d13e90e51"
      },
      "source": [
        "model = SWEMWithEmbeddings(\n",
        "    vocab_size = 194298,\n",
        "    embedding_size = 100, \n",
        "    hidden_dim1 = 80,\n",
        "    dim2 = 40, \n",
        "    num_outputs = 1,\n",
        ")\n",
        "weights=list(model.parameters())\n",
        "\n",
        "# Binary cross-entropy (BCE) Loss and Adam Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "# Iterate through train set minibatchs \n",
        "for epoch in range(100):\n",
        "    correct = 0\n",
        "    num_examples = 0\n",
        "    \n",
        "    #for (inputs,labels) in enumerate(train_dataloader):\n",
        "    for batch in train_dataloader:\n",
        "        # Zero out the gradients\n",
        "        inputs=batch.text\n",
        "        labels=batch.label\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        y = model(inputs)\n",
        "        yr = torch.round(y)\n",
        "       \n",
        "        \n",
        "        labels=labels.unsqueeze(1)\n",
        "        labels=labels.float()\n",
        "        labels=torch.sub(labels,1,alpha=1)\n",
        "        \n",
        "        loss = criterion(yr, labels)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        \n",
        "        correct += torch.sum((yr == labels).float())\n",
        "        num_examples += len(inputs)\n",
        "    \n",
        "    # Print training progress\n",
        "    if epoch % 1 == 0:\n",
        "        acc = correct/num_examples\n",
        "        print(weights[0].grad)\n",
        "        print(\"Epoch: {0} \\t Train Loss: {1} \\t Train Acc: {2}\".format(epoch, loss, acc))\n",
        "\n",
        "## Testing\n",
        "# correct = 0\n",
        "# num_test = 0\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     # Iterate through test set minibatchs \n",
        "#     for inputs, labels in test_loader:\n",
        "#         # Forward pass\n",
        "#         y = model(inputs)\n",
        "        \n",
        "#         predictions = torch.round(torch.sigmoid(y))\n",
        "#         correct += torch.sum((predictions == labels).float())\n",
        "#         num_test += len(inputs)\n",
        "    \n",
        "# print('Test accuracy: {}'.format(correct/num_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "Epoch: 0 \t Train Loss: 0.6931471824645996 \t Train Acc: 0.04577142745256424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a9f3a8077e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA0O_bVU3-aw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "fe6b5980-d8df-42b3-a990-fcadd8a3d823"
      },
      "source": [
        " from torch.nn.utils.rnn \n",
        "\n",
        "   \n",
        " ret = [glove.get_vecs_by_tokens(i.text)  for i in training_data[0:5]]\n",
        "   \n",
        " rets=pad_sequence(ret)\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-9011190bc579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[700, 5, 50]' is invalid for input of size 326000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZX-CDD2-dno",
        "outputId": "727b484d-b3e7-4189-cff8-a532d93e4ccc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([160, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "yCMZHAYg6E_K",
        "outputId": "9e68920d-7e02-494c-c588-3e497852cf80"
      },
      "source": [
        "ret = glove.get_vecs_by_tokens(TEXT, lower_case_backup=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-8462b9ad27b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vecs_by_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_case_backup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mget_vecs_by_tokens\u001b[0;34m(self, tokens, lower_case_backup)\u001b[0m\n\u001b[1;32m    468\u001b[0m             indices = [self[token] if token in self.stoi\n\u001b[1;32m    469\u001b[0m                        \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                        for token in tokens]\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    468\u001b[0m             indices = [self[token] if token in self.stoi\n\u001b[1;32m    469\u001b[0m                        \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                        for token in tokens]\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Vocab'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "WdqWzZ549Nm4",
        "outputId": "530de934-a014-4551-8729-43e9e7de4423"
      },
      "source": [
        "for batch in train_dataloader:\n",
        "  print(vec('hello'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-fe70edee843b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(self, vectors, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m                         \u001b[0;34m\"Got string input vector {}, but allowed pretrained \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                         \"vectors are {}\".format(\n\u001b[0;32m--> 183\u001b[0;31m                             vector, list(pretrained_aliases.keys())))\n\u001b[0m\u001b[1;32m    184\u001b[0m                 \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Got string input vector hello, but allowed pretrained vectors are ['charngram.100d', 'fasttext.en.300d', 'fasttext.simple.300d', 'glove.42B.300d', 'glove.840B.300d', 'glove.twitter.27B.25d', 'glove.twitter.27B.50d', 'glove.twitter.27B.100d', 'glove.twitter.27B.200d', 'glove.6B.50d', 'glove.6B.100d', 'glove.6B.200d', 'glove.6B.300d']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5B3O-SaVV3_"
      },
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, input_size, hidden_dim1,dim2, num_outputs):\n",
        "        super(Linear,self).__init__()\n",
        "       \n",
        "        self.fc1 = nn.Linear(input_size, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, dim2)\n",
        "        self.fc3 = nn.Linear(dim2,num_outputs)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        \n",
        "\n",
        "    def forward(self, text):\n",
        "        #text=self.embedding(text)\n",
        "        #text=text.view(text.size()[0],-1)\n",
        "        text=text.float()\n",
        "\n",
        "        h1 = self.fc1(text)\n",
        "        h1 = torch.sigmoid(h1)\n",
        "        h1= self.dropout(h1)\n",
        "        h2 = self.fc2(h1)\n",
        "        h2 = F.relu(h2)\n",
        "        h3 = self.fc3(h2)\n",
        "        \n",
        "        \n",
        "        return (h3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heiSI7ZAfDD6",
        "outputId": "90271aa3-1924-4ea9-c391-3ecc177b06a1"
      },
      "source": [
        "model = Linear(\n",
        "    input_size=700,\n",
        "    hidden_dim1 = 300,\n",
        "    dim2=100,\n",
        "    num_outputs = 1,\n",
        ")\n",
        "\n",
        "weights=list(model.parameters())\n",
        "for w in weights:\n",
        "  print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QkFpS6crr8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "354c2354-17f5-4ac7-ad24-159898ee607f"
      },
      "source": [
        "\n",
        "# Binary cross-entropy (BCE) Loss and Adam Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Iterate through train set minibatchs \n",
        "for epoch in range(500):\n",
        "    correct = 0\n",
        "    num_examples = 0\n",
        "    \n",
        "    #for (inputs,labels) in enumerate(train_dataloader):\n",
        "    for batch in train_dataloader:\n",
        "        # Zero out the gradients\n",
        "        #inputs=batch.text\n",
        "        \n",
        "        text=batch.text\n",
        "               \n",
        "        text=text.view(64,700)\n",
        "        labels=batch.label\n",
        "        #inputs=inputs.view(64,700)\n",
        "        #inputs=inputs.float()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        #y = model(inputs)\n",
        "        y=model(text)\n",
        "        yr = torch.squeeze(torch.round(torch.sigmoid(y)))\n",
        "        \n",
        "        yr=yr.float()\n",
        "        \n",
        "        labels=torch.sub(labels,1,alpha=1)\n",
        "        labels=labels.float()\n",
        "        \n",
        "        \n",
        "        loss = criterion(yr, labels)\n",
        "        \n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        \n",
        "        correct += torch.sum((yr == labels).float())\n",
        "        num_examples += len(text)\n",
        "    \n",
        "    # Print training progress\n",
        "    if epoch % 5 == 0:\n",
        "          \n",
        "        acc = (correct/num_examples)*100\n",
        "        print(weights[0].grad)\n",
        "        \n",
        "        print(\"Epoch: {0} \\t Train Loss: {1} \\t Train Acc: {2}\".format(epoch, loss, acc))\n",
        "        #print(\"Epoch: {0} \\t Train Loss: {1} \\t Correct: {2}\".format(epoch, loss, correct))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "Epoch: 0 \t Train Loss: 0.7119150161743164 \t Train Acc: 51.60576629638672\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "Epoch: 5 \t Train Loss: 0.739411473274231 \t Train Acc: 51.47595977783203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-9e3414dbac23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#for (inputs,labels) in enumerate(train_dataloader):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Zero out the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#inputs=batch.text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSrOPrTVsHMQ"
      },
      "source": [
        "for batch in train_dataloader:\n",
        "  print(glove.get_vecs_by_tokens(batch.text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_LRMCiqEFzZ"
      },
      "source": [
        "ret = [glove.get_vecs_by_tokens(i.text)  for i in training_data[0:5]]\n",
        "print(ret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMWyRs0aFocz",
        "outputId": "7b84b70e-f5b7-40e0-e2d2-5976eaa0271d"
      },
      "source": [
        "sentences=['hello','hi']\n",
        "print(glove.get_vecs_by_tokens(sentences[1]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.5431,  0.3443,  0.2713,  1.0487, -1.1642, -1.2722,  0.3578, -0.5653,\n",
            "        -0.2988,  0.8518,  0.5222, -0.0020, -0.4643,  0.0336,  0.0484,  0.7876,\n",
            "         0.0760,  0.5158,  0.3478,  0.5380,  0.2830, -0.1313, -0.0738,  0.4261,\n",
            "         0.0310, -0.5503, -0.9979, -0.2895,  0.3052, -1.1194,  1.2957,  0.9117,\n",
            "         0.3222,  0.9341, -0.3415, -0.6271, -0.0922,  0.5090,  0.2920, -0.2012,\n",
            "         0.1961, -0.4588,  1.1099, -0.6874,  1.5724, -0.1045,  0.2359, -0.5659,\n",
            "         0.4368,  0.9809])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH7AOlr6G922"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "   def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "     super().__init__()\n",
        "        \n",
        "     self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "     self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "     self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "   def forward(self, x):\n",
        "\n",
        "        #x = [sent len, batch size]\n",
        "        \n",
        "       embedded = self.embedding(x)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "       output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "       assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "       out = self.fc(hidden)\n",
        "       return out\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg2VUdml1JBQ"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 374\n",
        "OUTPUT_DIM = 2\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgrBOtNu1Z5e",
        "outputId": "7a0afa3b-b61d-4bab-e6b5-bfa89142037a"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([194298, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9nGBaj81wua"
      },
      "source": [
        "model.embedding.weight.data = pretrained_embeddings.cuda()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DrzM6ak11Q3"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ME94w__18TS"
      },
      "source": [
        "class_weights = torch.tensor([1.0, 15.0]).cuda()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOP5x6ec2FiZ"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(weight=class_weights)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkQM5IWfIm5l"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxl_00F2L6N"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    preds, ind= torch.max(F.softmax(preds, dim=-1), 1)\n",
        "    correct = (ind == y).float()\n",
        "    acc = correct.sum()/float(len(correct))\n",
        "    return acc"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKWriuRC2VSn"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        labels=batch.label       \n",
        "        predictions = model(batch.text).squeeze(0)\n",
        "        labels=torch.sub(labels,1,alpha=1)\n",
        "#         print(predictions.shape, batch.Label.shape, model(batch.Text).shape)\n",
        "        loss = criterion(predictions, labels)\n",
        "#         print(loss.shape)\n",
        "        acc = binary_accuracy(predictions, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKRerj-F2c6W",
        "outputId": "fcabc4ce-5e31-4760-e39e-1531c78dea78"
      },
      "source": [
        "N_EPOCHS=50\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "    print(train_acc)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5966346153846154\n",
            "0.60875\n",
            "0.6151923076923077\n",
            "0.6221153846153846\n",
            "0.6273076923076923\n",
            "0.6479326923076923\n",
            "0.6460576923076923\n",
            "0.6534615384615384\n",
            "0.6474038461538462\n",
            "0.6566826923076923\n",
            "0.6507211538461538\n",
            "0.6645192307692308\n",
            "0.6689903846153846\n",
            "0.6722115384615385\n",
            "0.6693269230769231\n",
            "0.6695673076923077\n",
            "0.6739903846153846\n",
            "0.6547115384615385\n",
            "0.6432211538461539\n",
            "0.6597596153846154\n",
            "0.6789903846153846\n",
            "0.6851923076923077\n",
            "0.6870673076923077\n",
            "0.683125\n",
            "0.6726923076923077\n",
            "0.6650480769230769\n",
            "0.6776923076923077\n",
            "0.6599038461538461\n",
            "0.6767788461538462\n",
            "0.6845673076923077\n",
            "0.6892307692307692\n",
            "0.6848557692307692\n",
            "0.6781730769230769\n",
            "0.6715384615384615\n",
            "0.6608653846153846\n",
            "0.6789423076923077\n",
            "0.676826923076923\n",
            "0.6753846153846154\n",
            "0.6590384615384616\n",
            "0.6745192307692308\n",
            "0.6726442307692307\n",
            "0.6841346153846154\n",
            "0.6874038461538462\n",
            "0.6880288461538462\n",
            "0.6888942307692307\n",
            "0.689375\n",
            "0.692548076923077\n",
            "0.6771634615384615\n",
            "0.6885096153846154\n",
            "0.6107211538461539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVa4rIUQ2vWx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}