{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEnAD2ITc9ekddnzLeedGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amogh24/Fake_news/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ziiso-5CKxBR"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0enhIZELEuE",
        "outputId": "ffacf1c4-f1cc-40ca-8c00-798fb91a878d"
      },
      "source": [
        "drive.mount('/content/gdrive')\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuI3MxVBZfO0",
        "outputId": "da932a2c-7f99-4999-bc89-ad97ac193bd8"
      },
      "source": [
        "import sys\r\n",
        "import csv\r\n",
        "\r\n",
        "csv.field_size_limit(sys.maxsize)\r\n",
        "csv.field_size_limit(100000000)\r\n",
        "csv.field_size_limit(sys.maxsize)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuOtcsmELZKS"
      },
      "source": [
        "import pandas as pd\r\n",
        "raw_news=pd.read_csv('/content/gdrive/MyDrive/fake-news/train.csv',engine='python')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEF7OzmPZPqr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8ea137f1-c5db-45a6-9843-10d02fc46c70"
      },
      "source": [
        "raw_news.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "1   1  ...     0\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEoM-ig1Zy3v"
      },
      "source": [
        "true_raw_news=raw_news[raw_news['label']==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p28ny4xtaCYN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "88ae776c-0cc8-4787-eda1-e0f6d0807fd7"
      },
      "source": [
        "true_raw_news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
              "      <td>Daniel Nussbaum</td>\n",
              "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
              "      <td>Alissa J. Rubin</td>\n",
              "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Excerpts From a Draft Script for Donald Trump’...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Donald J. Trump is scheduled to make a highly ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
              "      <td>Megan Twohey and Scott Shane</td>\n",
              "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "1   1  ...     0\n",
              "5   5  ...     0\n",
              "7   7  ...     0\n",
              "8   8  ...     0\n",
              "9   9  ...     0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwfuxvyYbq-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c372529a-ff7b-4977-e172-fed328bc774d"
      },
      "source": [
        "fake_raw_news=raw_news[raw_news['label']==1]\r\n",
        "fake_raw_news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "6   6  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDy-4neFbyXV"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF8QhMiHcLXn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "a04fab56-fefc-4936-c22d-9bcb827556b7"
      },
      "source": [
        "target = raw_news['label']\r\n",
        "sns.set_style('darkgrid')\r\n",
        "sns.countplot(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f120b1e2610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ZdSYEAgPW4"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9z-xaG6Gnwf"
      },
      "source": [
        "import torchtext"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDIXaFmX3Vnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dbb7699-a6aa-4f66-e1f5-564efd277459"
      },
      "source": [
        "\r\n",
        "import string\r\n",
        "import nltk\r\n",
        "import re\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "\r\n",
        "lemmatizer = WordNetLemmatizer()\r\n",
        "\r\n",
        "punct = set(string.punctuation)\r\n",
        "t={'\\n'}\r\n",
        "stopwords = set(stopwords.words('english'))\r\n",
        "#s=stopwords.union(punct)\r\n",
        "s=punct.union(t)\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsRY2AElHKTg"
      },
      "source": [
        "import spacy\r\n",
        "spacy_en = spacy.load('en')\r\n",
        "\r\n",
        "def tokenizer(text): # create a tokenizer function\r\n",
        "\r\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\r\n",
        "\r\n",
        "#TEXT = torchtext.data.Field(preprocessing=getClearReview,sequential=True, lower=True,tokenize=tokenizer)\r\n",
        "TEXT = torchtext.legacy.data.Field(sequential=True, lower=True,tokenize=tokenizer,use_vocab=True,stop_words=s,fix_length=700)\r\n",
        "#TEXT = torchtext.data.Field(sequential=True, lower=True,use_vocab=True,fix_length=700)\r\n",
        "LABEL = torchtext.legacy.data.Field(sequential=False, use_vocab=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmobdrOfHoG-"
      },
      "source": [
        "fields = [(None, None),(None, None),(None, None), ('text',TEXT),('label', LABEL)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40pI2kT-kgLD"
      },
      "source": [
        "training_data=torchtext.legacy.data.TabularDataset(path = '/content/gdrive/MyDrive/fake-news/train.csv',format = 'csv',fields = fields,skip_header = True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s4o9aTJk7pI"
      },
      "source": [
        "#print(vars(training_data.examples[0]))\r\n",
        "TEXT.build_vocab(training_data)\r\n",
        "LABEL.build_vocab(training_data)\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORvmBwKR9V4U"
      },
      "source": [
        "# TEXT.build_vocab(training_data, vectors=\"/content/gdrive/MyDrive/fake-news/glove.42B.300d.txt\")\r\n",
        "import numpy as np\r\n",
        "wordVector = {}\r\n",
        "glove_file=\"/content/gdrive/MyDrive/glove.42B.300d.txt\"\r\n",
        "with open(glove_file,'r') as f:\r\n",
        "  for line in f:\r\n",
        "    line_ = line.strip()\r\n",
        "    words_Vec = line_.split()\r\n",
        "    wordVector[words_Vec[0]] = np.array(words_Vec[1:],dtype=float)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpt2HGFmN_ZE",
        "outputId": "5514e2d4-d23d-4e62-9c68-a8e46f60fb4e"
      },
      "source": [
        "all = list(wordVector.keys())\r\n",
        "print(all[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[',', 'the', '.', 'and', 'to', 'of', 'a', 'in', '\"', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyVrRkziAuOu"
      },
      "source": [
        "def convert(line):\r\n",
        " \r\n",
        "  y = line.label\r\n",
        "  embeddings = [wordVector[word]  for word in line.text if word in all]\r\n",
        "  x=np.vstack(embeddings)\r\n",
        "  return x ,y \r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h24RYzLxlAO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "1b83525a-35c4-4d71-fbca-3b8fc42b1bf8"
      },
      "source": [
        "xs=[]\r\n",
        "ys=[]\r\n",
        "for line in training_data[:90]:\r\n",
        "  x,y=convert(line)\r\n",
        "  if(len(x)>0):\r\n",
        "    xs.append(x)\r\n",
        "    ys.append(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-5b1670cb6f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-b3da4ae57abb>\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwordVector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-czyIo0qhqZV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "5c8448db-e9dd-4764-dc60-2ae511e5e700"
      },
      "source": [
        "print((training_data[0].text))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-e4a5b2a58ae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iaj0IDqO35g"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "VOCAB_SIZE = 700\r\n",
        "EMBED_DIM = 64\r\n",
        "\r\n",
        "embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pR-fMD7UW67",
        "outputId": "12d37c67-caf8-4b0c-ad2b-b88ca4acd8a5"
      },
      "source": [
        "embedding.weight.size()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5000, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynBgS8efUrI_"
      },
      "source": [
        "class SWEMWithEmbeddings(nn.Module):\r\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_dim, num_outputs):\r\n",
        "        super().__init__()\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\r\n",
        "        self.fc1 = nn.Linear(embedding_size, hidden_dim)\r\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_outputs)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.embedding(x)\r\n",
        "        x = torch.mean(x, dim=0)\r\n",
        "        x = self.fc1(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.fc2(x)\r\n",
        "        return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bzpyd7KWDcx"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUQoHly0uNv1",
        "outputId": "966aea27-e798-443f-ec6b-d3519957a162"
      },
      "source": [
        "train_iter = torchtext.legacy.data.BucketIterator(\r\n",
        "    \r\n",
        "                              # Datasets for iterator to draw data from\r\n",
        "                              (training_data),\r\n",
        "\r\n",
        "                              # Tuple of train and validation batch sizes.\r\n",
        "                              batch_size=64,\r\n",
        "\r\n",
        "                              # Device to load batches on.\r\n",
        "                              device=-1, \r\n",
        "\r\n",
        "                              # Function to use for sorting examples.\r\n",
        "                              sort_key=lambda x: len(x.text),\r\n",
        "\r\n",
        "\r\n",
        "                              # Repeat the iterator for multiple epochs.\r\n",
        "                              #repeat=True, \r\n",
        "\r\n",
        "                              # Sort all examples in data using `sort_key`.\r\n",
        "                              sort=False, \r\n",
        "\r\n",
        "                              # Shuffle data on each epoch run.\r\n",
        "                              shuffle=True,\r\n",
        "\r\n",
        "                              # Use `sort_key` to sort examples in each batch.\r\n",
        "                              sort_within_batch=True,\r\n",
        "                              )\r\n",
        "\r\n",
        "# Print number of batches in each split.\r\n",
        "print('Created `train_iter` with %d batches!'%len(train_iter))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Created `train_iter` with 325 batches!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bDJJp-nRrId",
        "outputId": "8fbc8b61-451b-4d04-b097-403793783881"
      },
      "source": [
        "\r\n",
        "print(type(train_iter))\r\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchtext.legacy.data.iterator.BucketIterator'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5bbJPgQSaTn",
        "outputId": "dade7ff1-6507-4209-daf3-eaed020616f8"
      },
      "source": [
        "\r\n",
        "train_dataloader = (train_iter)\r\n",
        "\r\n",
        "for i in train_iter:\r\n",
        "  print(i.text.shape)\r\n",
        "\r\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n",
            "torch.Size([700, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFesNSaHTFl4",
        "outputId": "9e3aba5c-dadb-43e1-d9b0-4c3156065572"
      },
      "source": [
        "iterator = train_dataloader\r\n",
        "print(len(list(iterator)))\r\n",
        "print(type(list(iterator)))\r\n",
        "print(iterator)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "325\n",
            "<class 'list'>\n",
            "<torchtext.legacy.data.iterator.BucketIterator object at 0x7f4f3f4cd550>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "y1dsoWDOv3le",
        "outputId": "3d60dcc5-14ab-4535-8e32-14502a5c96a7"
      },
      "source": [
        "model = SWEMWithEmbeddings(\r\n",
        "    vocab_size = 700,\r\n",
        "    embedding_size = 64, \r\n",
        "    hidden_dim = 64, \r\n",
        "    num_outputs = 1,\r\n",
        ")\r\n",
        "\r\n",
        "# Binary cross-entropy (BCE) Loss and Adam Optimizer\r\n",
        "criterion = nn.BCEWithLogitsLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\r\n",
        "\r\n",
        "# Iterate through train set minibatchs \r\n",
        "for epoch in range(3):\r\n",
        "    correct = 0\r\n",
        "    num_examples = 0\r\n",
        "    \r\n",
        "    #for (inputs,labels) in enumerate(train_dataloader):\r\n",
        "    for batch in train_dataloader:\r\n",
        "        # Zero out the gradients\r\n",
        "        inputs=batch.text\r\n",
        "        labels=batch.label\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        # Forward pass\r\n",
        "        y = model(inputs)\r\n",
        "        labels=labels.unsqueeze(1)\r\n",
        "        labels=labels.float()\r\n",
        "        \r\n",
        "        loss = criterion(y, labels)\r\n",
        "        \r\n",
        "        # Backward pass\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        predictions = torch.round(torch.sigmoid(y))\r\n",
        "        correct += torch.sum((predictions == labels).float())\r\n",
        "        num_examples += len(inputs)\r\n",
        "    \r\n",
        "    # Print training progress\r\n",
        "    if epoch % 25 == 0:\r\n",
        "        acc = correct/num_examples\r\n",
        "        print(\"Epoch: {0} \\t Train Loss: {1} \\t Train Acc: {2}\".format(epoch, loss, acc))\r\n",
        "\r\n",
        "## Testing\r\n",
        "correct = 0\r\n",
        "num_test = 0\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    # Iterate through test set minibatchs \r\n",
        "    for inputs, labels in test_loader:\r\n",
        "        # Forward pass\r\n",
        "        y = model(inputs)\r\n",
        "        \r\n",
        "        predictions = torch.round(torch.sigmoid(y))\r\n",
        "        correct += torch.sum((predictions == labels).float())\r\n",
        "        num_test += len(inputs)\r\n",
        "    \r\n",
        "print('Test accuracy: {}'.format(correct/num_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-8842d4392948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-596190391745>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    145\u001b[0m         return F.embedding(\n\u001b[1;32m    146\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA0O_bVU3-aw"
      },
      "source": [
        " for (inputs,labels) in enumerate(train_dataloader):\r\n",
        "   print(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCMZHAYg6E_K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}